{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function\r\n",
      "import numpy as np\r\n",
      "import pandas as pd\r\n",
      "import cv2 \r\n",
      "import scipy\r\n",
      "\r\n",
      "import matplotlib.pyplot as plt; plt.rcdefaults()\r\n",
      "import numpy as np\r\n",
      "import matplotlib.pyplot as plt\r\n",
      "\r\n",
      "import os\r\n",
      "import os.path\r\n",
      "import random \r\n",
      "\r\n",
      "from math import sqrt\r\n",
      "from skimage import data\r\n",
      "from skimage.feature import blob_log\r\n",
      "from skimage.color import rgb2gray\r\n",
      "\r\n",
      "\r\n",
      "#The following code reads the image and performs laplacian of gaussian computer vision algorithm. \r\n",
      "#The graph is also created as a part of the function. \r\n",
      "from PIL import Image\r\n",
      "\r\n",
      "def check_shape(image):\r\n",
      "    image = cv2.imread(image)\r\n",
      "    height, width, channels = image.shape \r\n",
      "    if (height*width > 330000000):\r\n",
      "        return find_blobs_out(image, 7)\r\n",
      "    else:\r\n",
      "        \r\n",
      "        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\r\n",
      "        _,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)\r\n",
      "    \r\n",
      "        contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\r\n",
      "        cnt = contours[0]\r\n",
      "        x,y,w,h = cv2.boundingRect(cnt)\r\n",
      "        \r\n",
      "        image = image[y:y+h,x:x+w]\r\n",
      "        \r\n",
      "        return find_blobs_focus(image, 7)\r\n",
      "\r\n",
      "def splice_image(image, x, y):\r\n",
      "    test = image\r\n",
      "    my_slice = test[x:y, x:y]\r\n",
      "    return my_slice\r\n",
      "\r\n",
      "#Pick random number of positions in image and detects blobs \r\n",
      "def find_blobs_out(image, num):\r\n",
      "    array = []\r\n",
      "    #image = cv2.imread(image)\r\n",
      "    height, width, channels = image.shape\r\n",
      "    if(width>15000):\r\n",
      "        image = cv2.resize(image, dsize=(10000, 10000), interpolation=cv2.INTER_LINEAR)\r\n",
      "    placer = num - 1\r\n",
      "    X = width/300\r\n",
      "    Xfirst = 0\r\n",
      "    Y = X+height/300\r\n",
      "    Yfirst = X\r\n",
      "    for i in range(placer):\r\n",
      "        x_pick = int(random.uniform(Xfirst, X))\r\n",
      "        y_pick = int(random.uniform(Yfirst, Y))\r\n",
      "        array.append(LOGandDOG(splice_image(image, x_pick, y_pick)))\r\n",
      "        Xfirst = X\r\n",
      "        Yfirst = Y\r\n",
      "        X = X + width/300\r\n",
      "        Y = X+height/300\r\n",
      "    return array\r\n",
      "\r\n",
      "def find_blobs_focus(image, num):\r\n",
      "    array = []\r\n",
      "    #image = cv2.imread(image)\r\n",
      "    height, width, channels = image.shape\r\n",
      "    placer = num - 1\r\n",
      "    X = width/50\r\n",
      "    Xfirst = 0\r\n",
      "    Y = X+height/50\r\n",
      "    Yfirst = X\r\n",
      "    for i in range(placer):\r\n",
      "        x_pick = int(random.uniform(Xfirst, X))\r\n",
      "        y_pick = int(random.uniform(Yfirst, Y))\r\n",
      "        array.append(LOGandDOG(splice_image(image, x_pick, y_pick)))\r\n",
      "        Xfirst = X\r\n",
      "        Yfirst = Y\r\n",
      "        X = X + width/50\r\n",
      "        Y = X+height/50\r\n",
      "    return array\r\n",
      "\r\n",
      "def LOGandDOG(image): \r\n",
      "    #Reading image\r\n",
      "    #image = cv2.imread(image)\r\n",
      "    \r\n",
      "    blobsLOG = blob_log(rgb2gray(image), max_sigma=30, num_sigma=10, threshold=.1)\r\n",
      "\r\n",
      "    # Computing radii\r\n",
      "    blobsLOG[:, 2] = blobsLOG[:, 2] * sqrt(2)\r\n",
      "\r\n",
      "\r\n",
      "    #Setting plot\r\n",
      "    blobList = [blobsLOG]\r\n",
      "    colors = ['yellow']\r\n",
      "    titles = ['Laplacian of Gaussian']\r\n",
      "    sequence = zip(blobList, colors, titles)\r\n",
      "\r\n",
      "    fig, axes = plt.subplots(1, 2, figsize=(16, 9), sharex=True, sharey=True)\r\n",
      "\r\n",
      "    ax = axes.ravel()\r\n",
      "    \r\n",
      "    #print(\"Loading image...\")\r\n",
      "    countofCircles = 0\r\n",
      "    \r\n",
      "    for index, (blobs, color, title) in enumerate(sequence):\r\n",
      "        ax[index].set_title(title)\r\n",
      "        ax[index].imshow(image, interpolation='nearest')\r\n",
      "        for blob in blobs:\r\n",
      "            y, x, r = blob\r\n",
      "            c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\r\n",
      "            countofCircles=countofCircles+1\r\n",
      "            ax[index].add_patch(c)\r\n",
      "        ax[index].set_axis_off()\r\n",
      "        \r\n",
      "    #plt.show()\r\n",
      "    #print('This is the count for the number of Laplacian blobs: ', countofCircles)\r\n",
      "    return countofCircles \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import random \n",
    "\n",
    "from math import sqrt\n",
    "from skimage import data\n",
    "from skimage.feature import blob_log\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "!cat testing.py\n",
    "\n",
    "from testing import check_shape \n",
    "\n",
    "def analyze_image(image):\n",
    "    # Model reconstruction from JSON file\n",
    "    with open('model.json', 'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "\n",
    "    # Load weights into the new model\n",
    "    model.load_weights('model.h5')\n",
    "    \n",
    "    data = check_shape(image)\n",
    "    x = np.array(data).reshape((-1,1))\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    x = sc.fit_transform(x)\n",
    "    \n",
    "    x = np.array(data).reshape((1,6))\n",
    "    \n",
    "    prediction = model.predict(x)\n",
    "    \n",
    "    if (prediction <1): \n",
    "        return False \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_image(\"TestingImages/focus100.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlhub_sdk.client import DLHubClient\n",
    "\n",
    "dl = DLHubClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_serv = dl.search_by_servable(servable_name=\"candle*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 6], \"dtype\": \"float32\", \"units\": 10, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4\", \"backend\": \"tensorflow\"}"
     ]
    }
   ],
   "source": [
    "!cat model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 16:02:53.797104 4628809152 deprecation_wrapper.py:119] From /anaconda2/envs/model1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0813 16:02:53.820645 4628809152 deprecation_wrapper.py:119] From /anaconda2/envs/model1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0813 16:02:53.865688 4628809152 deprecation_wrapper.py:119] From /anaconda2/envs/model1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0813 16:02:53.866487 4628809152 deprecation_wrapper.py:119] From /anaconda2/envs/model1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0813 16:02:53.867173 4628809152 deprecation_wrapper.py:119] From /anaconda2/envs/model1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('model.json', 'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlhub_sdk.models.servables.keras import KerasModel\n",
    "import pickle as pkl\n",
    "import json\n",
    "import keras\n",
    "\n",
    "model_info = KerasModel.create_model('model.h5', arch_path='model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dlhub_sdk.models.servables.keras.KerasModel at 0xb33743b70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the model\n",
    "model_info.set_title(\"NN_Model\")\n",
    "model_info.set_name(\"neural_network\")\n",
    "model_info.set_domains([\"neuroscience\",\"machine learning\"])\n",
    "\n",
    "# Add dependencies\n",
    "model_info.add_requirement('keras', 'detect')\n",
    "model_info.add_requirement('numpy', 'detect')\n",
    "model_info.add_requirement('pandas', 'detect')\n",
    "model_info.add_requirement('cv2', 'detect')\n",
    "model_info.add_requirement('scipy', 'detect')\n",
    "model_info.add_requirement('matplotlib', 'detect')\n",
    "\n",
    "model_info.add_requirement('skimage', 'detect')\n",
    "model_info.add_requirement('sklearn', 'detect')\n",
    "\n",
    "# Describe the outputs in more detail\n",
    "model_info['servable']['methods']['run']['output']['description'] = 'Output'\n",
    "model_info['servable']['methods']['run']['input']['description'] = 'Input'\n",
    "\n",
    "# Add provenance information\n",
    "model_info.set_authors([\"Team, Globus\"], [\"Aarthi Koripelly\"])\n",
    "model_info.set_abstract(\"Image recognizing model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datacite\": {\n",
      "    \"creators\": [\n",
      "      {\n",
      "        \"givenName\": \"CANDLE\",\n",
      "        \"familyName\": \"Team\",\n",
      "        \"affiliations\": \"CANDLE\"\n",
      "      },\n",
      "      {\n",
      "        \"givenName\": \"Globus\",\n",
      "        \"familyName\": \"Team\",\n",
      "        \"affiliations\": \"Aarthi Koripelly\"\n",
      "      }\n",
      "    ],\n",
      "    \"titles\": [\n",
      "      {\n",
      "        \"title\": \"NN_Model\"\n",
      "      }\n",
      "    ],\n",
      "    \"publisher\": \"DLHub\",\n",
      "    \"publicationYear\": \"2019\",\n",
      "    \"identifier\": {\n",
      "      \"identifier\": \"10.YET/UNASSIGNED\",\n",
      "      \"identifierType\": \"DOI\"\n",
      "    },\n",
      "    \"descriptions\": [\n",
      "      {\n",
      "        \"description\": \"Image recognizing model.\",\n",
      "        \"descriptionType\": \"Abstract\"\n",
      "      }\n",
      "    ],\n",
      "    \"fundingReferences\": [],\n",
      "    \"relatedIdentifiers\": [],\n",
      "    \"alternateIdentifiers\": [\n",
      "      {\n",
      "        \"alternateIdentifier\": \"https://github.com/ECP-CANDLE/Benchmarks/tree/release_01/Pilot1/P1B1\",\n",
      "        \"alternateIdentifierType\": \"URL\"\n",
      "      }\n",
      "    ],\n",
      "    \"rightsList\": [],\n",
      "    \"resourceType\": {\n",
      "      \"resourceTypeGeneral\": \"InteractiveResource\"\n",
      "    }\n",
      "  },\n",
      "  \"dlhub\": {\n",
      "    \"version\": \"0.8.0\",\n",
      "    \"domains\": [\n",
      "      \"neuroscience\",\n",
      "      \"machine learning\"\n",
      "    ],\n",
      "    \"visible_to\": [\n",
      "      \"public\"\n",
      "    ],\n",
      "    \"name\": \"neural_network\",\n",
      "    \"files\": {\n",
      "      \"model\": \"model.h5\",\n",
      "      \"arch\": \"model.json\"\n",
      "    },\n",
      "    \"type\": \"servable\",\n",
      "    \"dependencies\": {\n",
      "      \"python\": {\n",
      "        \"keras\": \"2.2.4\",\n",
      "        \"h5py\": \"2.9.0\",\n",
      "        \"numpy\": \"1.16.2\",\n",
      "        \"pandas\": \"0.24.2\",\n",
      "        \"cv2\": \"4.1.0\",\n",
      "        \"scipy\": \"1.2.1\",\n",
      "        \"matplotlib\": \"3.0.3\",\n",
      "        \"skimage\": \"0.14.2\",\n",
      "        \"sklearn\": \"0.20.3\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"servable\": {\n",
      "    \"methods\": {\n",
      "      \"run\": {\n",
      "        \"input\": {\n",
      "          \"type\": \"ndarray\",\n",
      "          \"description\": \"Input\",\n",
      "          \"shape\": [\n",
      "            null,\n",
      "            6\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"ndarray\",\n",
      "          \"description\": \"Output\",\n",
      "          \"shape\": [\n",
      "            null,\n",
      "            1\n",
      "          ]\n",
      "        },\n",
      "        \"parameters\": {},\n",
      "        \"method_details\": {\n",
      "          \"method_name\": \"predict\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"shim\": \"keras.KerasServable\",\n",
      "    \"type\": \"Keras Model\",\n",
      "    \"model_summary\": \"_________________________________________________________________\\nLayer (type)                 Output Shape              Param #   \\n=================================================================\\ndense_1 (Dense)              (None, 10)                70        \\n_________________________________________________________________\\ndense_2 (Dense)              (None, 1)                 11        \\n=================================================================\\nTotal params: 81\\nTrainable params: 81\\nNon-trainable params: 0\\n_________________________________________________________________\\n\",\n",
      "    \"model_type\": \"Deep NN\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print out the result\n",
    "print(json.dumps(model_info.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = dl.publish_servable(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5dd60d2a-d290-434b-8c5b-a492bc4668b4'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
