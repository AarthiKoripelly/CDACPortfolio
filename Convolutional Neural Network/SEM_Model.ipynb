{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras import layers \n",
    "from keras import models\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense, Activation, Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import random \n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Building Convultional Neural Network using Tensorflow and Keras that detects blurry spots in SEM images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load DataSet\n",
    "train_focus_path = \"Testing_Focus_Images/\"\n",
    "train_outfocus_path = \"Testing_Outfocus_Images/\"\n",
    "\n",
    "training_set = []\n",
    "labels = []\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code reads the image and performs laplacian of gaussian computer vision algorithm. \n",
    "#The graph is also created as a part of the function. \n",
    "from PIL import Image\n",
    "\n",
    "def check_shape(image, label):\n",
    "    image = cv2.imread(image)\n",
    "    height, width, channels = image.shape \n",
    "\n",
    "    if (height*width > 330000000):\n",
    "        return large_classify(image, 20, label)\n",
    "    else:\n",
    "        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        _,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "        contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt = contours[0]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "    \n",
    "        image = image[y:y+h,x:x+w]\n",
    "        return small_classify(image, 20, label)\n",
    "\n",
    "def splice_image(image, x, y):\n",
    "    test = image\n",
    "    my_slice = test[x:y, x:y]\n",
    "    return my_slice\n",
    "\n",
    "#Pick random number of positions in image and detects blobs \n",
    "def large_classify(image, num, label):\n",
    "    image = cv2.resize(image, dsize=(10000, 10000))\n",
    "    #height, width, channels = image.shape\n",
    "    placer = num - 1\n",
    "    X = 100\n",
    "    Y = 120\n",
    "    image = rgb2gray(image)\n",
    "    for i in range(placer):\n",
    "        try:\n",
    "            im = splice_image(image, X, Y)\n",
    "            im = cv2.resize(im, dsize=(800, 800))\n",
    "            #im = splice_image(im, 1, 200)\n",
    "            #im = cv2.resize(im, dsize=(64, 64))\n",
    "            rotate = random.randint(0, 360)\n",
    "            im = im.rotate(rotate, expand=True)\n",
    "            training_set.append(im)\n",
    "            labels.append(label)\n",
    "            X = X+100\n",
    "            Y = Y+100\n",
    "        except: \n",
    "            continue\n",
    "\n",
    "def small_classify(image, num, label):\n",
    "    height, width, channels = image.shape\n",
    "    placer = num - 1\n",
    "    X = 1\n",
    "    Y = 900\n",
    "    image = rgb2gray(image)\n",
    "    for i in range(placer):\n",
    "        try:\n",
    "            im = splice_image(image, X, Y)\n",
    "            im = cv2.resize(im, dsize=(800, 800))\n",
    "            rotate = random.randint(0, 360)\n",
    "            im = im.rotate(rotate, expand=True)\n",
    "            training_set.append(im)\n",
    "            labels.append(label)\n",
    "            X = X+900\n",
    "            Y = Y+900\n",
    "        except -215:\n",
    "            print(\"skip\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Images to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Train Data \n",
    "i = 1\n",
    "for filename in os.listdir(train_focus_path):\n",
    "    print(str(i)+\".) \" + filename)\n",
    "    imagepath = train_focus_path + filename\n",
    "    check_shape(imagepath, 1)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for filename in os.listdir(train_outfocus_path):\n",
    "    print(str(i)+\".) \" + filename)\n",
    "    imagepath = train_outfocus_path + filename\n",
    "    check_shape(imagepath, 0) \n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating validation data \n",
    "train_set_stacked = np.stack(training_set)\n",
    "train_set_norm = train_set_stacked/255.\n",
    "label_cat = to_categorical(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_set_norm, label_cat, train_size=0.5, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape(-1,800, 800, 1)\n",
    "X_test = X_test.reshape(-1,800, 800, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_norm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My LeNet architecture\n",
    "model = Sequential()\n",
    "\n",
    "# conv filters of 5x5 each\n",
    "\n",
    "# Layer 1\n",
    "model.add(Convolution2D(200, (10,10), input_shape=(800, 800, 1), data_format='channels_last'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(10, 10)))  \n",
    "\n",
    "# Layer 2\n",
    "model.add(Convolution2D(150, 10, 10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Convolution2D(100, 5, 5))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    " \n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Layer 4 \n",
    "model.add(Dense(10))\n",
    "model.add(Dense(5))\n",
    "\n",
    "\n",
    "model.add(Dense(2))\n",
    "\n",
    "# Layer 5\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.08, decay=1e-6, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=6, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
